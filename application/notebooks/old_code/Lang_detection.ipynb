{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c977e4d-fffa-4e57-84ce-aa817fc62ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Dict, Any\n",
    "from copy import deepcopy\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report,roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import LongTensor, FloatTensor, HalfTensor, Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from copy import deepcopy\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import inspect\n",
    "\n",
    "import timm\n",
    "from catalyst import dl, utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cda0c84-b16a-41dd-8125-16232f3c1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for filename in glob.glob('prj/*.txt'): \n",
    "    filenames.append(filename.split('/')[-1].split('.')[0])\n",
    "filename = filenames[0]\n",
    "#filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc08c9e3-4c9f-49ad-8fc8-9e501b3bb5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_markup_pr_for_lang(filename):\n",
    "    df_audio = pd.read_csv(f'prj/{filename}.txt', sep='\t', header=None)\n",
    "    df_audio.columns=['start', 'end', 'person']\n",
    "    df_audio['len'] = df_audio['end'] - df_audio['start']\n",
    "    df_audio = df_audio[df_audio.person.isin(['su', 'sr', 'cu', 'cr'])].reset_index(drop=True)\n",
    "    df_audio['lang']  = df_audio['person'].apply(lambda row: row[1])\n",
    "    df_audio['person']  = df_audio['person'].apply(lambda row: row[0])\n",
    "    df_audio['filename'] = filename\n",
    "    return df_audio[['filename', 'start', 'end', 'len', 'lang']]\n",
    "\n",
    "\n",
    "All_audios = []\n",
    "for filename in filenames:\n",
    "    All_audios.append(read_markup_pr_for_lang(filename))\n",
    "All_audios = pd.concat(All_audios)\n",
    "All_audios = All_audios[All_audios['len'] > 1].reset_index(drop=True)\n",
    "All_audios['target'] = All_audios.lang.replace({'u':0, 'r':1})\n",
    "All_audios['path'] = All_audios.filename.apply(lambda x: f'prj/{filename}.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7b8203-677d-42d5-8398-033be414f79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 15, 37)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(All_audios, test_size=0.2, stratify=All_audios[['lang']].astype(str).apply('_'.join, axis=1), random_state=42)\n",
    "train, valid = train_test_split(train, test_size=0.1, stratify=train[['lang']].astype(str).apply('_'.join, axis=1), random_state=42)\n",
    "train.shape[0], valid.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "203406a5-bfc2-4dab-b281-29f0ad05b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.reset_index(drop=True)\n",
    "valid=valid.reset_index(drop=True)\n",
    "test=test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea60574c-ff85-49c6-8dfe-c041442936fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERIOD=5\n",
    "\n",
    "class Lang_Dataset(Dataset):\n",
    "    def __init__(self, dataset, target=None, idx=None, melspectrogram_parameters={}):\n",
    "        self.path = np.array(dataset.path)\n",
    "        if target is not None:\n",
    "            self.target = FloatTensor(np.array(target))\n",
    "        else:\n",
    "            self.target = None\n",
    "        self.index = idx\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "        self.start = dataset.start.values\n",
    "        self.end = dataset.end.values\n",
    "        self.sample_rate = 8000\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        y, sampling_rate = librosa.load(self.path[idx], sr=self.sample_rate, duration=60)\n",
    "        \n",
    "        y = y[int(self.sample_rate*self.start[idx]):int(self.sample_rate*self.end[idx])]\n",
    "        len_y = len(y)\n",
    "        effective_length = sampling_rate * PERIOD\n",
    "\n",
    "        if len_y < effective_length:\n",
    "            new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "            start = np.random.randint(effective_length - len_y)\n",
    "            new_y[start:start + len_y] = y\n",
    "            y = new_y.astype(np.float32)\n",
    "        elif len_y > effective_length:\n",
    "            start = np.random.randint(len_y - effective_length)\n",
    "            y = y[start:start + effective_length].astype(np.float32)\n",
    "        else:\n",
    "            y = y.astype(np.float32)\n",
    "        S = np.abs(librosa.stft(y));\n",
    "\n",
    "        melspec = librosa.power_to_db(S**2, ref=np.max)\n",
    "        \n",
    "        sample = {'features':  FloatTensor(np.expand_dims(melspec, 0))}\n",
    "        if self.target is not None:\n",
    "            sample['targets'] = self.target[idx]#labels.flatten()\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "520abdc9-e951-4fe0-b47e-97a1d01e8e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7ffa1bd878e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_temp = Lang_Dataset(train, train.target)\n",
    "smp = A_temp[10]\n",
    "img, labl = smp['features'].numpy(), smp['targets']\n",
    "librosa.display.specshow(img[0], sr=8000, x_axis='time', y_axis='hz')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00dfa2c1-9d60-4374-8e23-f1248c0db013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1025, 79)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f220d712-7481-4674-998b-539c861b62e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimmModel(nn.Module):\n",
    "    def __init__(self, name_of_model='tf_efficientnet_b0_ns', pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.img_model = timm.create_model(name_of_model, pretrained=pretrained, in_chans=1)\n",
    "        self.classifier = nn.Sequential(nn.ELU(), nn.Dropout(0.2), nn.Linear(in_features=1000, out_features=1))\n",
    "\n",
    "    def forward(self, features):\n",
    "        \n",
    "        return self.classifier(\n",
    "            self.img_model(\n",
    "                   features\n",
    "            )\n",
    "        ).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b96c38-82c2-42f8-96e4-06549089c815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct  4 20:55:58 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    41W / 250W |      4MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ced41ed-87e7-48fd-918a-3341192c193b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1d2b75399c40eaa86b63716b0e2f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/20 * Epoch (train):   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (1/20) auc: 0.5811111330986023 | auc/_macro: 0.5811111330986023 | auc/_micro: 0.5811111111111111 | auc/_weighted: 0.14527778327465057 | auc/class_00: 0.5811111330986023 | loss: 0.6173343658447266 | loss/mean: 0.6173343658447266 | loss/std: 0.02981703219295556 | lr: 1e-05 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee6f480a4e84356afd8fb9084a11cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/20 * Epoch (valid):   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (1/20) auc: 0.7222222089767456 | auc/_macro: 0.7222222089767456 | auc/_micro: 0.7222222222222221 | auc/_weighted: 0.14444445073604584 | auc/class_00: 0.7222222089767456 | loss: 0.5531836748123169 | loss/mean: 0.5531836748123169 | loss/std: 0.0 | lr: 1e-05 | momentum: 0.9\n",
      "* Epoch (1/20) lr: 1e-05 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c251f6b70054d5db2fab5df4b3bf71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2/20 * Epoch (train):   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (2/20) auc: 0.4468167722225189 | auc/_macro: 0.4468167722225189 | auc/_micro: 0.44681677018633537 | auc/_weighted: 0.1042572483420372 | auc/class_00: 0.4468167722225189 | loss: 0.6348111629486084 | loss/mean: 0.6348111629486084 | loss/std: 0.06927250656478569 | lr: 1e-05 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2a76d154c447f5a94f9d6eff770eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2/20 * Epoch (valid):   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (2/20) auc: 0.8055555820465088 | auc/_macro: 0.8055555820465088 | auc/_micro: 0.8055555555555556 | auc/_weighted: 0.16111111640930176 | auc/class_00: 0.8055555820465088 | loss: 0.7351803183555603 | loss/mean: 0.7351803183555603 | loss/std: 0.0 | lr: 1e-05 | momentum: 0.9\n",
      "* Epoch (2/20) lr: 1e-05 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77657899adc42389814e28b17d461cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3/20 * Epoch (train):   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (3/20) auc: 0.5125448107719421 | auc/_macro: 0.5125448107719421 | auc/_micro: 0.5125448028673835 | auc/_weighted: 0.11532258242368698 | auc/class_00: 0.5125448107719421 | loss: 0.6051254272460938 | loss/mean: 0.6051254272460938 | loss/std: 0.04979358840972906 | lr: 1e-05 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a86609c8644a07b3cf2aac3743a415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3/20 * Epoch (valid):   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (3/20) auc: 0.5555555820465088 | auc/_macro: 0.5555555820465088 | auc/_micro: 0.5555555555555556 | auc/_weighted: 0.111111119389534 | auc/class_00: 0.5555555820465088 | loss: 0.7345924973487854 | loss/mean: 0.7345924973487854 | loss/std: 0.0 | lr: 1e-05 | momentum: 0.9\n",
      "* Epoch (3/20) lr: 3e-06 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156daed90526402495f5e5cad1c83157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4/20 * Epoch (train):   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (4/20) auc: 0.47200000286102295 | auc/_macro: 0.47200000286102295 | auc/_micro: 0.472 | auc/_weighted: 0.09833332896232605 | auc/class_00: 0.47200000286102295 | loss: 0.6022875308990479 | loss/mean: 0.6022875308990479 | loss/std: 0.03806253150755584 | lr: 3e-06 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84b6ef507f54efa9c6493db5c4451b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4/20 * Epoch (valid):   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (4/20) auc: 0.5 | auc/_macro: 0.5 | auc/_micro: 0.5 | auc/_weighted: 0.10000000149011612 | auc/class_00: 0.5 | loss: 0.6012418270111084 | loss/mean: 0.6012418270111084 | loss/std: 0.0 | lr: 3e-06 | momentum: 0.9\n",
      "* Epoch (4/20) lr: 9e-07 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7458a96c80784b069ea255737cc4075c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5/20 * Epoch (train):   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (5/20) auc: 0.5135869383811951 | auc/_macro: 0.5135869383811951 | auc/_micro: 0.5135869565217391 | auc/_weighted: 0.1198369562625885 | auc/class_00: 0.5135869383811951 | loss: 0.6042546033859253 | loss/mean: 0.6042546033859253 | loss/std: 0.1060158826164727 | lr: 9e-07 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdb897862ec4759a994221b3a80856f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5/20 * Epoch (valid):   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (5/20) auc: 0.5833333134651184 | auc/_macro: 0.5833333134651184 | auc/_micro: 0.5833333333333333 | auc/_weighted: 0.11666666716337204 | auc/class_00: 0.5833333134651184 | loss: 0.5689816474914551 | loss/mean: 0.5689816474914551 | loss/std: 0.0 | lr: 9e-07 | momentum: 0.9\n",
      "* Epoch (5/20) lr: 2.6999999999999996e-07 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41de7cce31245418764252a123fafad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "6/20 * Epoch (train):   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (6/20) auc: 0.4658385217189789 | auc/_macro: 0.4658385217189789 | auc/_micro: 0.4658385093167702 | auc/_weighted: 0.10869565606117249 | auc/class_00: 0.4658385217189789 | loss: 0.6114551424980164 | loss/mean: 0.6114551424980164 | loss/std: 0.04335433632689891 | lr: 2.6999999999999996e-07 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e81ef3097df44c58e2478ac329d1910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "6/20 * Epoch (valid):   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (6/20) auc: 0.5833333134651184 | auc/_macro: 0.5833333134651184 | auc/_micro: 0.5833333333333333 | auc/_weighted: 0.11666666716337204 | auc/class_00: 0.5833333134651184 | loss: 0.556983232498169 | loss/mean: 0.556983232498169 | loss/std: 0.0 | lr: 2.6999999999999996e-07 | momentum: 0.9\n",
      "* Epoch (6/20) lr: 1e-07 | momentum: 0.9\n",
      "Top best models:\n",
      "Lang/New_dataset/checkpoints/train.2.pth\t0.8056\n",
      "Lang/New_dataset/checkpoints/train.1.pth\t0.7222\n",
      "Lang/New_dataset/checkpoints/train.5.pth\t0.5833\n"
     ]
    }
   ],
   "source": [
    "EXP_PATH = 'Lang/New_dataset'\n",
    "\n",
    "\n",
    "#for i, (fold_train, fold_val) in enumerate(cv_data):\n",
    "#print('Fold', i)\n",
    "#if i==0:\n",
    "FOLD_PATH = f'{EXP_PATH}'\n",
    "\n",
    "batch_size=20\n",
    "\n",
    "\n",
    "loaders = {\n",
    "    \"train\": DataLoader(Lang_Dataset(train, train['target']),\n",
    "                        worker_init_fn=worker_init_fn,\n",
    "                        batch_size=batch_size, shuffle=True, drop_last=True, num_workers=6, pin_memory=True),\n",
    "    \"valid\": DataLoader(Lang_Dataset(valid, valid['target']), \n",
    "                        worker_init_fn=worker_init_fn,\n",
    "                        batch_size=batch_size, shuffle=False, drop_last=False, num_workers=1, pin_memory=True),\n",
    "}\n",
    "\n",
    "model =  TimmModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=0, factor=0.3, min_lr=1e-7)\n",
    "\n",
    "callbacks = [\n",
    "    dl.AUCCallback(input_key=\"logits\", target_key=\"targets\",),\n",
    "#     dl.AccuracyCallback(\n",
    "#             input_key=\"logits\", target_key=\"targets\", num_classes=2\n",
    "#         ),\n",
    "    dl.OptimizerCallback('loss'),\n",
    "    dl.SchedulerCallback(loader_key='valid', metric_key='auc', mode='epoch'),\n",
    "    dl.CheckpointCallback(loader_key='valid', metric_key='auc', minimize=False, save_n_best=3, mode='model', use_runner_logdir=True, use_logdir_postfix=True, ),\n",
    "    dl.EarlyStoppingCallback(patience=4, loader_key=\"valid\", metric_key=\"auc\", minimize=False),\n",
    "    dl.TimerCallback()\n",
    "]\n",
    "runner = dl.SupervisedRunner(input_key=\"features\", target_key=\"targets\", output_key=\"logits\", loss_key=\"loss\", )\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=loaders,\n",
    "    num_epochs=20,#99999,#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    callbacks=callbacks,\n",
    "    #engine=dl.DeviceEngine(\"cpu\"),\n",
    "    logdir=f\"{FOLD_PATH}\",\n",
    "    valid_loader=\"valid\",\n",
    "    valid_metric=\"auc\",\n",
    "    minimize_valid_metric=False,\n",
    "    verbose=True,\n",
    "    load_best_on_end=True,\n",
    "    amp=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56bafcb3-78aa-4a5f-9cc1-6bfcd4bd0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_loader(model, loader):\n",
    "    pred = runner.predict_loader(model=model, loader=loader)\n",
    "    #pred = [torch.sigmoid(batch['logits'].detach().cpu().float()).numpy() for batch in tqdm(pred)] \n",
    "    pred = [batch['logits'].detach().cpu().float().numpy() for batch in tqdm(pred)] \n",
    "    pred = pd.Series(np.concatenate(pred, 0), index = loader.dataset.index)\n",
    "    return pred\n",
    "    \n",
    "def get_valid_logs(exp_path='logs'):\n",
    "    valid_log = pd.read_csv(f'{exp_path}/logs/valid.csv')#.set_index('step')\n",
    "    if ('step' == valid_log['step']).any():\n",
    "        valid_log = valid_log.iloc[valid_log[valid_log['step'] == 'step'].index.max()+1:].reset_index(drop=True)\n",
    "    return valid_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56ad2a65-d025-4819-aede-46ce2dc6b9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f517965a02f4a449394324ea48dcf25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7837837837837838\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = DataLoader(Lang_Dataset(test, test['target']), \n",
    "                    #worker_init_fn=worker_init_fn,\n",
    "                    batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2, pin_memory=False)\n",
    "model =  TimmModel()\n",
    "model.load_state_dict(torch.load(f'{EXP_PATH}/checkpoints/best.pth')['model_state_dict'])\n",
    "model = model.eval().cuda()\n",
    "score = get_valid_logs(EXP_PATH)['auc'].max()\n",
    "#pred = predict_loader(model, test_dataloader)\n",
    "#write_prediction(pred, f'best_{score}', EXP_PATH)\n",
    "\n",
    "pred = runner.predict_loader(model=model, loader=test_dataloader)\n",
    "#pred = [torch.sigmoid(batch['logits'].detach().cpu().float()).numpy() for batch in tqdm(pred)] \n",
    "pred = [batch['logits'].detach().cpu().float().numpy() for batch in tqdm(pred)] \n",
    "\n",
    "\n",
    "pred = pd.DataFrame(np.concatenate(pred, 0), index = test_dataloader.dataset.index)\n",
    "\n",
    "test['pred'] = pred.apply(lambda row: row.argmax(), axis=1).values\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(test.target, test.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d29f68-2954-4dbe-a995-d3e281714957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
